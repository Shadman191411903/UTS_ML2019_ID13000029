{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/shadmanspc/anaconda3/lib/python3.7/site-packages (2.22.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/shadmanspc/anaconda3/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/shadmanspc/anaconda3/lib/python3.7/site-packages (from requests) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/shadmanspc/anaconda3/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shadmanspc/anaconda3/lib/python3.7/site-packages (from requests) (2019.6.16)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "try:\n",
    "    import urllib.request as urllib2\n",
    "except ImportError:\n",
    "    import urllib2\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import algorithms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import QSTK.qstkfeat.featutil as ftu\n",
    "from pyalgotrade import strategy\n",
    "from pyalgotrade import barfeed\n",
    "from pyalgotrade import bar\n",
    "from pyalgotrade.technical import ma as pytechma\n",
    "from pyalgotrade import plotter\n",
    "from pyalgotrade.stratanalyzer import returns\n",
    "from pyalgotrade.stratanalyzer import sharpe\n",
    "from pyalgotrade.utils import stats as pytechstats\n",
    "import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shadmanspc/Desktop/ADA/assign2/0001.HK_training.csv\n",
      "{'open':                0001.HK\n",
      "2018-09-24  203.259995\n",
      "2018-09-25  202.199997\n",
      "2018-09-26  203.960007\n",
      "2018-09-27  201.029999\n",
      "2018-09-28  201.429993\n",
      "...                ...\n",
      "2019-08-26  208.479996\n",
      "2019-08-27  211.720001\n",
      "2019-08-28  211.949997\n",
      "2019-08-29  211.000000\n",
      "2019-08-30  215.889999\n",
      "\n",
      "[237 rows x 1 columns], 'high':                0001.HK\n",
      "2018-09-24  203.259995\n",
      "2018-09-25  203.789993\n",
      "2018-09-26  203.960007\n",
      "2018-09-27  204.000000\n",
      "2018-09-28  203.139999\n",
      "...                ...\n",
      "2019-08-26  211.399994\n",
      "2019-08-27  212.229996\n",
      "2019-08-28  213.860001\n",
      "2019-08-29  213.250000\n",
      "2019-08-30  219.449997\n",
      "\n",
      "[237 rows x 1 columns], 'low':                0001.HK\n",
      "2018-09-24  200.619995\n",
      "2018-09-25  200.720001\n",
      "2018-09-26  200.889999\n",
      "2018-09-27  200.309998\n",
      "2018-09-28  200.250000\n",
      "...                ...\n",
      "2019-08-26  207.720001\n",
      "2019-08-27  210.514999\n",
      "2019-08-28  211.000000\n",
      "2019-08-29  209.660004\n",
      "2019-08-30  214.160004\n",
      "\n",
      "[237 rows x 1 columns], 'close':                0001.HK\n",
      "2018-09-24  201.559998\n",
      "2018-09-25  203.300003\n",
      "2018-09-26  201.570007\n",
      "2018-09-27  200.600006\n",
      "2018-09-28  200.639999\n",
      "...                ...\n",
      "2019-08-26  208.699997\n",
      "2019-08-27  211.080002\n",
      "2019-08-28  213.589996\n",
      "2019-08-29  213.250000\n",
      "2019-08-30  218.000000\n",
      "\n",
      "[237 rows x 1 columns], 'volume':              0001.HK\n",
      "2018-09-24  118342.0\n",
      "2018-09-25  100526.0\n",
      "2018-09-26   82597.0\n",
      "2018-09-27  120231.0\n",
      "2018-09-28  116012.0\n",
      "...              ...\n",
      "2019-08-26  153934.0\n",
      "2019-08-27  185525.0\n",
      "2019-08-28  148214.0\n",
      "2019-08-29  206327.0\n",
      "2019-08-30  155411.0\n",
      "\n",
      "[237 rows x 1 columns], 'actual_close':                0001.HK\n",
      "2018-09-24  198.138657\n",
      "2018-09-25  199.849121\n",
      "2018-09-26  198.148483\n",
      "2018-09-27  197.194946\n",
      "2018-09-28  197.234268\n",
      "...                ...\n",
      "2019-08-26  206.950577\n",
      "2019-08-27  209.310638\n",
      "2019-08-28  211.799591\n",
      "2019-08-29  211.462448\n",
      "2019-08-30  216.172623\n",
      "\n",
      "[237 rows x 1 columns]}\n"
     ]
    }
   ],
   "source": [
    "download_dir = '/Users/shadmanspc/Desktop/ADA/assign2'\n",
    "# training data url for time 1 Apr, 2012 to 31 Mar, 2016\n",
    "#download_dir = 'C:\\Users\\user\\Desktop\\stck/'\n",
    "# training data url for time 1 Apr, 2012 to 31 Mar, 2016\n",
    "training_data_url = 'http://real-chart.finance.yahoo.com/table.csv?s=%s&a=03&b=1&c=2012&d=02&e=31&f=2016&g=d&ignore=.csv'\n",
    "# stocks used as training data, all stocks from 0060.HK to 0100.HK\n",
    "# change start and end to manipulate the data set\n",
    "start_stock = 1\n",
    "end_stock = 1\n",
    "stocks = []\n",
    "\n",
    "for counter in range(start_stock, end_stock + 1):\n",
    "    stocks.append('%04d.HK' % counter)\n",
    "\n",
    "\n",
    "\n",
    "# keys from yahoo are different from what qstk library expects\n",
    "yahoo_keys = ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
    "qstk_keys = ['open', 'high', 'low', 'close', 'volume', 'actual_close']\n",
    "\n",
    "raw_training_data = {}\n",
    "# cloned for iteration, will remove those stocks from master stocks list if\n",
    "# issue found during downloading data\n",
    "stocks_clone = [s for s in stocks]\n",
    "for s in stocks_clone:\n",
    "    file_name = download_dir + \"/\"+ s + '_training'+'.csv'\n",
    "    print(file_name)\n",
    "    if(os.path.isfile(file_name)) :\n",
    "        raw_training_data[s] = pd.read_csv(file_name)\n",
    "    else:\n",
    "        stock_url = training_data_url % s\n",
    "        try:\n",
    "            raw_training_data[s] = pd.read_csv(stock_url)\n",
    "            raw_training_data[s].to_csv(file_name, sep=',')\n",
    "        except (urllib2.HTTPError, urllib2.URLError) as ex:\n",
    "            print ('Not found %s stock when downloading training data' %s)\n",
    "            if s in stocks:\n",
    "                stocks.remove(s)\n",
    "            pass\n",
    "\n",
    "def sanitizedataforqstk(frame):\n",
    "    data = {}\n",
    "    for k in yahoo_keys:\n",
    "        key_df = pd.DataFrame()\n",
    "        for s in stocks:\n",
    "            dates = np.array([dt.datetime.strptime(t, \"%Y-%m-%d\") for t in frame[s]['Date']])\n",
    "            key_df[s] = pd.Series(data=frame[s][k].values, index=dates).sort_index(ascending=True)\n",
    "        data[k] = key_df\n",
    "\n",
    "    # sanitize to use the earlier keys\n",
    "    data[qstk_keys[0]] = data[yahoo_keys[0]]\n",
    "    data[qstk_keys[1]] = data[yahoo_keys[1]]\n",
    "    data[qstk_keys[2]] = data[yahoo_keys[2]]\n",
    "    data[qstk_keys[3]] = data[yahoo_keys[3]]\n",
    "    data[qstk_keys[4]] = data[yahoo_keys[4]]\n",
    "    data[qstk_keys[5]] = data[yahoo_keys[5]]\n",
    "    del data[yahoo_keys[0]]\n",
    "    del data[yahoo_keys[1]]\n",
    "    del data[yahoo_keys[2]]\n",
    "    del data[yahoo_keys[3]]\n",
    "    del data[yahoo_keys[4]]\n",
    "    del data[yahoo_keys[5]]\n",
    "    for key in qstk_keys:\n",
    "        data[key] = data[key].fillna(method='ffill')\n",
    "        data[key] = data[key].fillna(method='bfill')\n",
    "        data[key] = data[key].fillna(1.0)\n",
    "\n",
    "    return data\n",
    "\n",
    "training_data = sanitizedataforqstk(raw_training_data)\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featMA( dData, lLookback=30, bRel=True, b_human=False ):\n",
    "    '''\n",
    "    @summary: Calculate moving average\n",
    "    @param dData: Dictionary of data to use\n",
    "    @param lLookback: Number of days to look in the past\n",
    "    @param b_human: if true return dataframe to plot\n",
    "    @return: DataFrame array containing values\n",
    "    '''\n",
    "    \n",
    "    dfPrice = dData['close']\n",
    "    \n",
    "    dfRet = dfPrice.rolling(lLookback).mean()\n",
    "    #ts_log.rolling(12).mean()\n",
    "    \n",
    "    if bRel:\n",
    "        dfRet = dfRet / dfPrice\n",
    "    if b_human:  \n",
    "        data2 = dfRet * dData['close']\n",
    "        data3 = pand.DataFrame({\"Raw\":data2[data2.columns[0]]})\n",
    "        for sym in dfRet.columns:\n",
    "            if sym != '$SPX' and sym != '$VIX':\n",
    "                data3[sym + \" Moving Average\"] = data2[sym]\n",
    "                data3[sym] = dData['close'][sym]\n",
    "        del data3['Raw']\n",
    "        return data3\n",
    "    return dfRet\n",
    "\n",
    "ma_training=featMA(training_data,bRel=False).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0001.HK\n",
      "2018-09-24  0.000000\n",
      "2018-09-25  0.000000\n",
      "2018-09-26  0.000000\n",
      "2018-09-27  0.000000\n",
      "2018-09-28  0.000000\n",
      "...              ...\n",
      "2019-02-08  0.074845\n",
      "2019-02-11  0.072411\n",
      "2019-02-12  0.072334\n",
      "2019-02-13  0.045856\n",
      "2019-02-14  0.056200\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "def returnize0(nds):\n",
    "    \"\"\"\n",
    "    @summary Computes stepwise (usually daily) returns relative to 0, where\n",
    "    0 implies no change in value.\n",
    "    @return the array is revised in place\n",
    "    \"\"\"\n",
    "    s= np.shape(nds)\n",
    "    if len(s)==1:\n",
    "        nds=np.expand_dims(nds,1)\n",
    "    #print(s)\n",
    "    nds[1:, :] = (nds[1:, :] - nds[0:-1]) / abs(nds[0:-1])\n",
    "    nds[0, :] = np.zeros(nds.shape[1])\n",
    "    \n",
    "    #return nds\n",
    "\n",
    "def featMomentum(dData, lLookback=20, b_human=False ):\n",
    "    '''\n",
    "    @summary: N day cumulative return (based on 1) indicator\n",
    "    @param dData: Dictionary of data to use\n",
    "    @param lLookback: Number of days to look in the past\n",
    "    @param b_human: if true return dataframe to plot\n",
    "    @return: DataFrame array containing values\n",
    "    '''\n",
    "    if b_human:\n",
    "        for sym in dData['close']:\n",
    "            x=1000/dData['close'][sym][0]\n",
    "            dData['close'][sym]=dData['close'][sym]*x\n",
    "        return dData['close']\n",
    "    dfPrice = dData['close'].copy()\n",
    "    #print(dfPrice.values)\n",
    "    \n",
    "    #Calculate Returns\n",
    "    returnize0(dfPrice.values)\n",
    "    \n",
    "    #Calculate rolling sum\n",
    "    dfRet = dfPrice.rolling(lLookback).sum()\n",
    "    #print(dfRet.head(100))\n",
    "    \n",
    "    \n",
    "    return dfRet\n",
    "\n",
    "mom_training=featMomentum(training_data).fillna(0.0)\n",
    "print(mom_training.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featRSI( dData, lLookback=14,  b_human=False):\n",
    "    '''\n",
    "    @summary: Calculate RSI\n",
    "    @param dData: Dictionary of data to use\n",
    "    @param lLookback: Number of days to look in the past, 14 is standard\n",
    "    @param b_human: if true return dataframe to plot\n",
    "    @return: DataFrame array containing values\n",
    "    '''\n",
    "\n",
    "    # create deltas per day\n",
    "    delta = dData['close'].diff()\n",
    "    #-----------\n",
    "    dUp, dDown = delta.copy(), delta.copy()\n",
    "    dUp[dUp < 0] = 0\n",
    "    dDown[dDown > 0] = 0\n",
    "\n",
    "    RolUp = dUp.rolling(14).mean()\n",
    "    RolDown = dDown.rolling(14).mean().abs()\n",
    "    \n",
    "\n",
    "    RS = RolUp / RolDown\n",
    "    rsi= 100.0 - (100.0 / (1.0 + RS))\n",
    "    return rsi\n",
    "\n",
    "rsi_training=featRSI(training_data).fillna(0.0)\n",
    "#print(rsi_training.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shadmanspc/Desktop/ADA/assign2/0001.HK_current.csv\n"
     ]
    }
   ],
   "source": [
    "currentDataUrl = 'http://real-chart.finance.yahoo.com/table.csv?s=%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'\n",
    "currentDate = dt.date.today()\n",
    "oldDate = currentDate + dt.timedelta(days=-30)\n",
    "raw_current_data = {}\n",
    "for s in stocks_clone:\n",
    "    file_name = download_dir + \"/\"+ s + '_current'+'.csv'\n",
    "    print(file_name)\n",
    "    if(os.path.isfile(file_name)) :\n",
    "        raw_current_data[s] = pd.read_csv(file_name)\n",
    "    else:    \n",
    "        stock_url = currentDataUrl % (\n",
    "            s, '%02d' % (oldDate.month - 1), oldDate.day, oldDate.year, '%02d' % (currentDate.month - 1), currentDate.day,\n",
    "            currentDate.year)\n",
    "        try:\n",
    "            raw_current_data[s] = pd.read_csv(stock_url)\n",
    "            raw_current_data[s].to_csv(file_name, sep=',')\n",
    "        except (urllib2.HTTPError, urllib2.URLError) as ex:\n",
    "            #print 'Not found %s stock when downloading current data' %s\n",
    "            if s in stocks:\n",
    "                stocks.remove(s)\n",
    "            pass\n",
    "\n",
    "current_data = sanitizedataforqstk(raw_current_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "# basic initialization for deap\n",
    "def initDeap():\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "    # stochastic removed as High and Low can't be calculated for\n",
    "    IND_SIZE = 3  \n",
    "    # registerd coeff alias to coefficient function\n",
    "    toolbox.register(\"coeffs\", coefficient)\n",
    "    # individual alias registerd to tools.initRepeat\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.coeffs, n=IND_SIZE)\n",
    "    # population alias registered\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    # evaluate fucntion registered to computeFitness function\n",
    "    toolbox.register(\"evaluate\", compute_fitness)\n",
    "    toolbox.register(\"mate\", tools.cxSimulatedBinary, eta=0.3)\n",
    "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0.0, sigma=1.0, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=5)\n",
    "\n",
    "# 1. rsi, 2. ma, 3. mom above is the order of coefficients removed pivot\n",
    "# point and stochastic oscillator as one of the technical indicator, because\n",
    "# lets say we are running this for the next 6 months,in that case we would\n",
    "# not have the value of high, low of future. as such for future we can't use\n",
    "# it.\n",
    "def compute_fitness(individual):\n",
    "    error = 0.0\n",
    "    count = 0\n",
    "    for key in stocks:\n",
    "        # difference in RSI between day1 and day1 + 1\n",
    "        rsidiff = rsi_training[key] - rsi_training[key].shift()\n",
    "        # difference in moving average between day1 and day1 + 1\n",
    "        madiff = ma_training[key] - ma_training[key].shift()\n",
    "        # difference in momentum between day1 and day1 + 1\n",
    "        momdiff = mom_training[key] - mom_training[key].shift()\n",
    "        per_stock_count = 0\n",
    "        dataframe_index = training_data[qstk_keys[3]][key].index.tolist()\n",
    "        for (date, val) in rsi_training[key].iteritems():\n",
    "            next_day = dataframe_index[per_stock_count + 1] if\\\n",
    "                per_stock_count <= len(dataframe_index) - 1 else None\n",
    "            if not np.isnan(rsidiff[date]) and next_day is not None:\n",
    "                #            Fitness defined as\n",
    "                # market close (day2) - [ rsi difference between consecutive day * (coeff 1) +\n",
    "                # moving average difference between consecutive day * (coeff 2) +\n",
    "                # momentum difference between consecutive day * (coeff 3) +\n",
    "                \n",
    "                # Objective is to minimize the summation of squares of the above differences\n",
    "                ft = (rsidiff[date]) * individual[0] + (madiff[date]) * individual[1] \\\n",
    "                     + (momdiff[date]) * individual[2]\n",
    "                ft = ft + training_data[qstk_keys[3]][key][date]\n",
    "                error = error + np.square(training_data[qstk_keys[3]][key][next_day] - ft)\n",
    "                count = count + 1\n",
    "                per_stock_count = per_stock_count + 1\n",
    "    # dividing by total count gives the mean square error, which we want to minimize\n",
    "    return (error / count,)\n",
    "\n",
    "\n",
    "def coefficient():\n",
    "    return random.random()\n",
    "\n",
    "def predict(individual, days=1):\n",
    "    prediction_series= []\n",
    "    for d in list(range(days)):\n",
    "        # calculate the rsi, ma and momentum\n",
    "        # with each preddiction the underluing current_data dataframe is updated,\n",
    "        # so we get the updated rsi for all the days\n",
    "        rsi_current = featRSI(current_data).fillna(0.0)\n",
    "        ma_current = featMA(current_data, bRel=False).fillna(0.0)\n",
    "        mom_current = featMomentum(current_data).fillna(0.0)\n",
    "\n",
    "        for key in stocks:\n",
    "            # get the last valid date for which data is present\n",
    "            last_date_with_data =\\\n",
    "                current_data[qstk_keys[3]][key].last_valid_index()\n",
    "            next_date = last_date_with_data + dt.timedelta(days=1)\n",
    "            # calculate the rsi,ma and momentum diff across consecutive days \n",
    "            rsi_current_diff = rsi_current[key] - rsi_current[key].shift()\n",
    "            #print(\"rsi_diff\")\n",
    "            #print(rsi_current_diff)\n",
    "            \n",
    "            ma_current_diff = ma_current[key] - ma_current[key].shift()\n",
    "            #print(\"ma_diff\")\n",
    "            #print(ma_current_diff)\n",
    "            mom_current_diff = mom_current[key] - mom_current[key].shift()\n",
    "            #print(\"mom_diff\")\n",
    "            #print(mom_current_diff)\n",
    "            #  calculate the deviation based on the conefficients\n",
    "            deviation = (rsi_current_diff.tail(1).values[0]) * individual[0]\\\n",
    "                + (ma_current_diff.tail(1).values[0]) * individual[1]+\\\n",
    "                (mom_current_diff.tail(1).values[0]) * individual[2]\n",
    "            print(deviation)\n",
    "            # predicted is addition of deviation + current close\n",
    "            predicted_close_next_day = deviation + current_data[qstk_keys[3]][key][last_date_with_data]\n",
    "            # update the current dataframe so we can continue calculating stocks\n",
    "            current_data[qstk_keys[3]][key].set_value(next_date,predicted_close_next_day)\n",
    "            \n",
    "            prediction_series.append((key,next_date,predicted_close_next_day,\n",
    "                                      current_data[qstk_keys[3]][key][last_date_with_data] ,\n",
    "                                      deviation))\n",
    "    \n",
    "    return prediction_series\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg    \tmin    \tmax    \tstd    \tmedian \n",
      "0  \t50    \t70.8557\t5.24258\t179.055\t41.1901\t63.6673\n",
      "1  \t29    \t45.713 \t4.99853\t321.197\t70.3728\t26.3387\n",
      "2  \t35    \t15.6609\t0.604514\t157.619\t24.0518\t7.42354\n",
      "3  \t22    \t4.46469\t0.0786569\t10.4546\t2.16965\t4.99853\n",
      "4  \t26    \t12.0652\t0.0557195\t419.839\t59.0746\t1.04479\n",
      "5  \t27    \t0.506957\t0.0386586\t3.46404\t0.728329\t0.26086\n",
      "Best individual is: [0.012015262712115471, 0.01400118069072751, 0.8666123177653835]\n",
      "with fitness: (0.038658563251895504,)\n",
      "0.018968253604333803\n",
      "0.018968253604333803\n",
      "0.018968253604333803\n",
      "[('0001.HK', Timestamp('2019-09-21 00:00:00'), 208.17897225360434, 208.16000400000001, 0.018968253604333803), ('0001.HK', Timestamp('2019-09-22 00:00:00'), 208.19794050720867, 208.17897225360434, 0.018968253604333803), ('0001.HK', Timestamp('2019-09-23 00:00:00'), 208.216908760813, 208.19794050720867, 0.018968253604333803)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shadmanspc/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:94: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    initDeap()\n",
    "    # population generated\n",
    "    pop = toolbox.population(n=50)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"median\", np.median)\n",
    "    # built in algo used with cross over probability = 0.5, mutation probability = 0.2 and number of generation = 5\n",
    "    pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=5, stats=stats, halloffame=hof,\n",
    "                                       verbose=True)\n",
    "    print(\"Best individual is: %s\\nwith fitness: %s\" % (hof[0], hof[0].fitness))\n",
    "    # this gives us the coefficients. Once we get the coefficients , we can use this coefficients,\n",
    "    # we can use these to calculate the next day's value based on values on the present day\n",
    "    \n",
    "    # predict for 5 days, change the number of days to get that many days of prediction\n",
    "    prediction_series = predict(hof[0],days=3)\n",
    "    # sorting the prediction series with all entries of same stock together\n",
    "   \n",
    "    prediction_series_sorted = sorted(prediction_series, key=lambda tup: tup[0])\n",
    "    print(prediction_series)\n",
    "    filename = download_dir+'/results_predicted12.csv'\n",
    "    with open(filename, 'w') as csvfile:\n",
    "        fieldnames = ['stock',\n",
    "                      'date','predicted_price','price_prev_day','deviation','movement']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for prediction in prediction_series_sorted:\n",
    "            movement = 'DOWN' if prediction[4] < 0 else 'UP'\n",
    "            writer.writerow(\n",
    "                {'stock': prediction[0], 'date': prediction[1].strftime('%m/%d/%Y'),'predicted_price': prediction[2],'price_prev_day': prediction[3],'deviation':prediction[4],'movement':movement})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
