{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Choosing the best parameters for the model</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========BEGIN============\n",
      "0\n",
      "gen\tnevals\tavg    \tmin     \tmax    \tstd    \tmedian \n",
      "0  \t50    \t13.6118\t0.158951\t45.6127\t14.1334\t8.21695\n",
      "1  \t26    \t2.04605\t0.158951\t15.0742\t2.88806\t0.860443\n",
      "2  \t23    \t0.388392\t0.158951\t2.22606\t0.321743\t0.280114\n",
      "3  \t35    \t2.77125 \t0.0320672\t126.114\t17.6224 \t0.187358\n",
      "4  \t24    \t0.139434\t0.00496736\t0.696298\t0.104651\t0.155043\n",
      "5  \t29    \t0.0608498\t0.00348368\t0.278795\t0.0507767\t0.033952\n",
      "Best individual is: [0.007584669599713454, 0.0034004473577601974, 0.974725125608459]\n",
      "with fitness: (0.0034836786291230254,)\n",
      "lets see\n",
      "['0.0034836786291230254']\n",
      "The best fitness from \n",
      "1. 50 -populationSize \n",
      "2. 0.500000 -crossOverPropability                \n",
      "3. 0.200000 -mutationProbability\n",
      "4. 5.000000 -numberOfGeneration \n",
      "5. 0.003484 -error\n",
      "===============DONE===================================\n",
      "===========BEGIN============\n",
      "1\n",
      "gen\tnevals\tavg    \tmin     \tmax    \tstd    \tmedian \n",
      "0  \t60    \t15.0974\t0.118008\t46.2058\t12.6679\t12.9648\n",
      "1  \t34    \t3.19692\t0.118008\t35.0149\t5.37516\t1.55336\n",
      "2  \t36    \t0.808105\t0.117047\t30.7533\t3.90401\t0.272977\n",
      "3  \t39    \t0.95055 \t0.0819156\t30.3875\t4.45868\t0.122312\n",
      "4  \t38    \t0.286968\t0.0778241\t9.01113\t1.15326\t0.11461 \n",
      "5  \t47    \t0.783091\t0.0608846\t21.1278\t3.68721\t0.0961536\n",
      "6  \t21    \t0.0828469\t0.035275 \t0.167848\t0.0218276\t0.0802849\n",
      "7  \t35    \t1.30596  \t0.0211433\t58.8189 \t7.60096  \t0.0647191\n",
      "Best individual is: [0.007584669599713454, 0.0034004473577601974, 0.974725125608459]\n",
      "with fitness: (0.0034836786291230254,)\n",
      "lets see\n",
      "['0.0034836786291230254']\n",
      "===============DONE===================================\n",
      "===========BEGIN============\n",
      "2\n",
      "gen\tnevals\tavg    \tmin      \tmax   \tstd    \tmedian \n",
      "0  \t70    \t16.5254\t0.0644064\t43.417\t13.4084\t13.9652\n",
      "1  \t51    \t5.09831\t0.0111491\t70.0768\t9.64182\t2.20154\n",
      "2  \t48    \t6.63591\t0.0111491\t220.839\t35.9755\t0.191605\n",
      "3  \t53    \t0.886804\t0.00967964\t25.4786\t3.70765\t0.0839005\n",
      "4  \t50    \t0.0656583\t0.00470782\t0.661217\t0.0907594\t0.0541373\n",
      "5  \t45    \t0.0193334\t0.00428173\t0.0782369\t0.0159877\t0.0111491\n",
      "6  \t50    \t0.0295112\t0.00428173\t1.40844  \t0.166045 \t0.00972342\n",
      "7  \t56    \t0.00692822\t0.00254248\t0.0221529\t0.00294694\t0.00644368\n",
      "8  \t61    \t1.41865   \t0.00217323\t97.8632  \t11.6112   \t0.00449453\n",
      "9  \t52    \t0.00378627\t0.00173915\t0.00831064\t0.0012206 \t0.0035607 \n",
      "Best individual is: [0.005016465207663991, -0.010504180352686557, 0.8625838400204994]\n",
      "with fitness: (0.0017391528646972904,)\n",
      "lets see\n",
      "['0.0017391528646972904']\n",
      "The best fitness from \n",
      "1. 70 -populationSize \n",
      "2. 0.600000 -crossOverPropability                \n",
      "3. 0.300000 -mutationProbability\n",
      "4. 9.000000 -numberOfGeneration \n",
      "5. 0.001739 -error\n",
      "===============DONE===================================\n",
      "===========BEGIN============\n",
      "3\n",
      "gen\tnevals\tavg    \tmin      \tmax    \tstd    \tmedian \n",
      "0  \t80    \t16.6777\t0.0811934\t46.4111\t14.5218\t11.9456\n",
      "1  \t58    \t4.27243\t0.0694122\t26.865 \t5.78858\t1.85254\n",
      "2  \t66    \t5.2963 \t0.078656 \t180.427\t23.6261\t0.330225\n",
      "3  \t53    \t2.13282\t0.0154249\t133.876\t14.9647\t0.150849\n",
      "4  \t57    \t0.443912\t0.0120111\t26.0098\t2.89023\t0.0867166\n",
      "5  \t57    \t0.535013\t0.00118808\t14.7505\t2.47836\t0.0491169\n",
      "6  \t56    \t0.564783\t0.00118808\t33.0541\t3.69358\t0.0154249\n",
      "7  \t61    \t0.0522352\t0.000238756\t2.59002\t0.292002\t0.00827666\n",
      "8  \t60    \t2.28416  \t0.000238756\t165.716\t18.4205 \t0.00317677\n",
      "9  \t59    \t1.05803  \t0.000238756\t43.3772\t5.75607 \t0.00118022\n",
      "10 \t67    \t4.05145  \t0.000169509\t213.751\t25.4956 \t0.000586174\n",
      "11 \t65    \t2.17712  \t0.000113954\t173.03 \t19.2228 \t0.000238756\n",
      "Best individual is: [0.00015633028645739038, -0.0037361671384887364, 0.6847566044084644]\n",
      "with fitness: (0.0001139536327380431,)\n",
      "lets see\n",
      "['0.0001139536327380431']\n",
      "The best fitness from \n",
      "1. 80 -populationSize \n",
      "2. 0.650000 -crossOverPropability                \n",
      "3. 0.350000 -mutationProbability\n",
      "4. 11.000000 -numberOfGeneration \n",
      "5. 0.000114 -error\n",
      "===============DONE===================================\n",
      "===========BEGIN============\n",
      "4\n",
      "gen\tnevals\tavg    \tmin     \tmax    \tstd    \tmedian\n",
      "0  \t90    \t17.5282\t0.119222\t45.7677\t13.8607\t13.452\n",
      "1  \t70    \t15.257 \t0.0820798\t320.066\t50.266 \t2.46683\n",
      "2  \t69    \t1.23589\t0.0660425\t24.3256\t2.97792\t0.693163\n",
      "3  \t76    \t0.849895\t0.0345136\t25.218 \t3.28729\t0.142397\n",
      "4  \t73    \t1.21552 \t0.0100947\t99.2142\t10.3884\t0.072062\n",
      "5  \t77    \t0.371412\t0.00208605\t25.7442\t2.6976 \t0.053815\n",
      "6  \t72    \t1.07592 \t0.00195755\t63.6945\t7.0005 \t0.0266194\n",
      "7  \t77    \t0.0898685\t0.000403683\t4.0357 \t0.444258\t0.00893868\n",
      "8  \t74    \t0.496527 \t0.000140435\t31.943 \t3.46874 \t0.00238422\n",
      "9  \t84    \t0.0663186\t0.000104658\t2.07787\t0.321328\t0.00175825\n",
      "10 \t66    \t0.368612 \t9.90888e-05\t33.1167\t3.47129 \t0.000380666\n",
      "11 \t77    \t0.0728959\t4.39241e-05\t4.73055\t0.528706\t0.000135652\n",
      "12 \t65    \t0.274971 \t3.303e-05  \t13.913 \t1.59099 \t0.000109989\n",
      "13 \t73    \t0.00384118\t9.94647e-06\t0.336881\t0.0353023\t6.98116e-05\n",
      "Best individual is: [8.441176054247516e-05, -0.0015729309100646002, 0.17650643125453128]\n",
      "with fitness: (9.946465601928282e-06,)\n",
      "lets see\n",
      "['9.946465601928282']\n",
      "===============DONE===================================\n",
      "===========BEGIN============\n",
      "5\n",
      "gen\tnevals\tavg    \tmin      \tmax    \tstd    \tmedian \n",
      "0  \t100   \t17.8588\t0.0471193\t46.0378\t14.2565\t15.6594\n",
      "1  \t86    \t8.97359\t0.0327723\t176.261\t25.23  \t1.81332\n",
      "2  \t84    \t2.8957 \t0.000168293\t101.412\t10.8481\t0.15221\n",
      "3  \t84    \t2.03153\t0.00033999 \t53.5642\t8.92189\t0.0529948\n",
      "4  \t86    \t0.361365\t0.00026461 \t31.8261\t3.1651 \t0.0195645\n",
      "5  \t82    \t0.00822343\t2.89359e-05\t0.108054\t0.0176628\t0.00232239\n",
      "6  \t77    \t0.0209175 \t2.89359e-05\t1.96864 \t0.195756 \t0.00112394\n",
      "7  \t83    \t0.0110323 \t2.43927e-05\t0.642954\t0.0692422\t0.000267767\n",
      "8  \t93    \t0.00106859\t1.82051e-05\t0.0804094\t0.00799616\t8.06474e-05\n",
      "9  \t84    \t1.05898   \t1.50694e-05\t60.5657  \t7.23725   \t4.39754e-05\n",
      "10 \t87    \t0.877947  \t7.50031e-06\t58.942   \t6.4037    \t2.45447e-05\n",
      "11 \t93    \t3.31678   \t7.54352e-06\t227.864  \t23.2981   \t1.89807e-05\n",
      "12 \t88    \t0.0496531 \t4.95457e-06\t2.43464  \t0.30711   \t1.42003e-05\n",
      "13 \t88    \t1.58364   \t3.01708e-06\t110.341  \t11.4209   \t9.72732e-06\n",
      "14 \t91    \t0.076445  \t1.42712e-06\t5.18984  \t0.530812  \t7.33669e-06\n",
      "15 \t85    \t1.15366   \t6.04295e-07\t70.3961  \t7.98901   \t5.42876e-06\n",
      "Best individual is: [-0.00011759068777908093, 0.00034334127267140953, 0.020756292694297032]\n",
      "with fitness: (6.042954125819921e-07,)\n",
      "lets see\n",
      "['6.042954125819921']\n",
      "===============DONE===================================\n",
      "===========BEGIN============\n",
      "6\n",
      "gen\tnevals\tavg    \tmin     \tmax    \tstd    \tmedian \n",
      "0  \t110   \t15.8324\t0.063196\t45.3814\t13.9837\t12.0286\n",
      "1  \t98    \t3.27169\t0.00690822\t29.0012\t5.53846\t1.42493\n",
      "2  \t98    \t2.82967\t0.00690822\t51.3498\t8.23637\t0.440881\n",
      "3  \t95    \t1.14862\t0.000154572\t55.5869\t6.12163\t0.0815095\n",
      "4  \t100   \t1.51327\t0.000142484\t150.179\t14.2485\t0.033484 \n",
      "5  \t97    \t1.92671\t0.000142484\t98.7847\t13.1165\t0.01289  \n",
      "6  \t93    \t2.12417\t0.000142484\t85.5503\t12.6788\t0.00483337\n",
      "7  \t102   \t0.905256\t0.000141273\t41.6761\t4.64853\t0.00196586\n",
      "8  \t103   \t3.23284 \t2.9107e-06 \t316.512\t30.1043\t0.000714341\n",
      "9  \t101   \t0.241021\t1.49674e-05\t26.3887\t2.5045 \t0.000286297\n",
      "10 \t97    \t0.3506  \t1.13246e-07\t36.4147\t3.4588 \t0.000143706\n",
      "11 \t102   \t2.53041 \t1.13246e-07\t211.245\t20.5605\t3.72488e-05\n",
      "12 \t100   \t2.25328 \t1.13246e-07\t156.871\t15.9247\t1.9167e-05 \n",
      "13 \t105   \t0.485423\t5.08528e-08\t43.4356\t4.17594\t7.20533e-06\n",
      "14 \t100   \t4.20233 \t1.98142e-08\t259.425\t26.8518\t4.20904e-07\n",
      "15 \t105   \t0.289802\t6.80019e-09\t28.0256\t2.67028\t1.14111e-07\n",
      "16 \t97    \t1.22315 \t6.56077e-09\t89.4058\t9.24015\t8.7082e-08 \n",
      "17 \t101   \t0.110428\t2.04567e-09\t11.1855\t1.06425\t3.37291e-08\n",
      "Best individual is: [1.1871664769710849e-07, -3.800331148992608e-05, -0.0016574118663036826]\n",
      "with fitness: (2.0456744206110477e-09,)\n",
      "lets see\n",
      "['2.0456744206110477']\n",
      "===============DONE===================================\n",
      "===========BEGIN============\n",
      "7\n",
      "gen\tnevals\tavg   \tmin     \tmax    \tstd    \tmedian \n",
      "0  \t120   \t14.492\t0.154989\t46.0741\t13.3821\t9.09154\n",
      "1  \t113   \t6.59035\t0.0393899\t124.457\t16.4624\t1.87036\n",
      "2  \t112   \t1.40718\t0.0252271\t43.1265\t4.09045\t0.579935\n",
      "3  \t119   \t5.41423\t0.0132544\t438.858\t40.8202\t0.27569 \n",
      "4  \t112   \t1.01719\t0.0104702\t90.1647\t8.19511\t0.125917\n",
      "5  \t108   \t2.87105\t0.00374618\t190.867\t20.1068\t0.0431834\n",
      "6  \t108   \t1.53153\t0.00190943\t176.207\t16.0165\t0.0169961\n",
      "7  \t112   \t2.8733 \t0.000994339\t201.252\t20.2022\t0.00787295\n",
      "8  \t113   \t1.07882\t0.000210769\t122.906\t11.1739\t0.00408499\n",
      "9  \t113   \t0.0282986\t2.75522e-05\t1.58668\t0.154563\t0.00189642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \t111   \t1.68356  \t1.78762e-05\t143.941\t13.8468 \t0.00113696\n",
      "11 \t115   \t3.18479  \t6.48373e-06\t138.264\t16.6475 \t0.000361319\n",
      "12 \t109   \t0.0934507\t5.98692e-06\t2.64022\t0.401232\t0.000140294\n",
      "13 \t111   \t1.16734  \t3.83136e-06\t136.261\t12.3875 \t3.82942e-05\n",
      "14 \t117   \t0.55857  \t2.34286e-06\t50.3114\t4.65168 \t1.25987e-05\n",
      "15 \t109   \t0.372319 \t1.20741e-06\t16.5127\t2.04619 \t7.65526e-06\n",
      "16 \t114   \t0.998547 \t7.58287e-07\t93.4387\t8.64917 \t4.50007e-06\n",
      "17 \t111   \t0.23556  \t2.09756e-07\t21.4192\t2.02711 \t3.3009e-06 \n",
      "18 \t109   \t2.01476  \t1.7979e-07 \t173.922\t16.9223 \t2.32101e-06\n",
      "19 \t113   \t1.45344  \t1.97692e-07\t114.062\t10.9725 \t1.5566e-06 \n",
      "Best individual is: [1.1871664769710849e-07, -3.800331148992608e-05, -0.0016574118663036826]\n",
      "with fitness: (2.0456744206110477e-09,)\n",
      "lets see\n",
      "['2.0456744206110477']\n",
      "===============DONE===================================\n",
      "===========BEGIN============\n",
      "8\n",
      "gen\tnevals\tavg    \tmin     \tmax    \tstd    \tmedian\n",
      "0  \t130   \t19.0571\t0.334699\t45.3874\t13.7619\t18.29 \n",
      "1  \t124   \t80.5629\t0.093681\t4740.62\t563.255\t3.02781\n",
      "2  \t122   \t2.36745\t0.0618994\t101.002\t9.13225\t0.966623\n",
      "3  \t123   \t10.1996\t0.00692468\t291.82 \t41.9608\t0.365647\n",
      "4  \t124   \t10.6688\t0.000426607\t361.47 \t48.9154\t0.204756\n",
      "5  \t123   \t1.61518\t7.24889e-05\t138.38 \t12.176 \t0.0681477\n",
      "6  \t125   \t0.986269\t6.31593e-05\t56.9809\t5.93104\t0.0178772\n",
      "7  \t127   \t0.978122\t1.46309e-05\t53.4552\t5.65852\t0.00288509\n",
      "8  \t125   \t1.33023 \t1.12565e-05\t90.6567\t10.1709\t0.000545802\n",
      "9  \t125   \t1.41557 \t6.26854e-06\t181.672\t15.8712\t0.000138082\n",
      "10 \t123   \t3.13226 \t2.42731e-06\t162.485\t18.9535\t4.69102e-05\n",
      "11 \t122   \t1.04481 \t1.04327e-06\t134.335\t11.7359\t1.34486e-05\n",
      "12 \t127   \t3.67035 \t1.08105e-07\t464.553\t40.5832\t4.26262e-06\n",
      "13 \t124   \t0.954188\t1.66279e-07\t97.2861\t8.59885\t2.62469e-06\n",
      "14 \t126   \t2.04633 \t1.07886e-07\t141.336\t15.8705\t1.88031e-06\n",
      "15 \t123   \t0.381648\t1.11587e-08\t21.8468\t2.33968\t1.10622e-06\n",
      "16 \t128   \t4.12414 \t1.11587e-08\t245.88 \t25.7304\t3.63824e-07\n",
      "17 \t121   \t2.35777 \t5.45996e-10\t96.0547\t13.3488\t1.1243e-07 \n",
      "18 \t127   \t0.940418\t1.14306e-10\t102.157\t9.02353\t2.98184e-08\n",
      "19 \t122   \t1.90942 \t1.35626e-10\t186.392\t16.8135\t1.13323e-08\n",
      "20 \t127   \t1.80222 \t1.30055e-10\t141.384\t13.6088\t4.20149e-09\n",
      "21 \t125   \t2.90628 \t2.99508e-11\t343.725\t30.0471\t1.37272e-09\n",
      "Best individual is: [-4.382836413967563e-07, -1.0109194073770308e-06, 0.00043228336997132354]\n",
      "with fitness: (2.995082069152705e-11,)\n",
      "lets see\n",
      "['2.995082069152705']\n",
      "===============DONE===================================\n",
      "===========BEGIN============\n",
      "9\n",
      "gen\tnevals\tavg    \tmin       \tmax    \tstd    \tmedian \n",
      "0  \t140   \t16.9109\t0.00976335\t45.7477\t15.0008\t11.7228\n",
      "1  \t138   \t2.9602 \t0.0150321 \t46.2484\t5.18702\t1.36641\n",
      "2  \t139   \t1.97808\t0.0100658 \t56.7272\t7.43801\t0.379861\n",
      "3  \t138   \t227.683\t0.00286496\t15842.3\t1876.57\t0.150195\n",
      "4  \t135   \t0.654839\t0.00077351\t65.3886\t5.53628\t0.0241533\n",
      "5  \t137   \t0.90242 \t0.000323433\t92.0689\t7.81276\t0.0122222\n",
      "6  \t139   \t3.74546 \t0.000131642\t320.093\t28.2329\t0.00614471\n",
      "7  \t137   \t0.360776\t8.43404e-05\t37.4045\t3.19427\t0.00158121\n",
      "8  \t137   \t0.375662\t2.62147e-05\t39.7049\t3.41885\t0.000718761\n",
      "9  \t138   \t0.456391\t2.03831e-05\t37.5299\t3.57146\t0.000315707\n",
      "10 \t137   \t2.49715 \t1.46843e-05\t142.971\t16.8186\t0.000181704\n",
      "11 \t138   \t2.72614 \t7.98703e-06\t183.978\t19.5244\t8.77585e-05\n",
      "12 \t136   \t0.649958\t2.78395e-06\t72.2483\t6.12656\t5.23205e-05\n",
      "13 \t140   \t4.58009 \t1.89313e-06\t276.583\t28.7723\t2.53751e-05\n",
      "14 \t140   \t1.96467 \t1.34432e-06\t180.715\t16.6395\t1.17631e-05\n",
      "15 \t139   \t3.32381 \t4.48618e-07\t222.785\t23.5511\t5.3819e-06 \n",
      "16 \t135   \t0.89143 \t7.75614e-08\t47.3731\t5.33751\t3.97203e-06\n",
      "17 \t139   \t3.2091  \t3.51631e-08\t109.34 \t16.4739\t1.9137e-06 \n",
      "18 \t140   \t0.38223 \t2.64352e-08\t30.8327\t2.79722\t1.13707e-06\n",
      "19 \t140   \t1.95277 \t4.89105e-09\t147.347\t13.4299\t4.35076e-07\n",
      "20 \t138   \t1.57504 \t4.97959e-09\t88.7633\t9.77251\t2.03481e-07\n",
      "21 \t139   \t0.181916\t1.53194e-09\t8.58491\t1.05027\t9.62295e-08\n",
      "22 \t136   \t0.447516\t7.83911e-10\t40.917 \t3.64337\t2.49056e-08\n",
      "23 \t132   \t2.6094  \t2.63302e-10\t126.393\t15.9751\t7.24233e-09\n",
      "Best individual is: [-4.382836413967563e-07, -1.0109194073770308e-06, 0.00043228336997132354]\n",
      "with fitness: (2.995082069152705e-11,)\n",
      "lets see\n",
      "['2.995082069152705']\n",
      "===============DONE===================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "try:\n",
    "    import urllib.request as urllib2\n",
    "except ImportError:\n",
    "    import urllib2\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import algorithms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import QSTK.qstkfeat.featutil as ftu\n",
    "from pyalgotrade import strategy\n",
    "from pyalgotrade import barfeed\n",
    "from pyalgotrade import bar\n",
    "from pyalgotrade.technical import ma as pytechma\n",
    "from pyalgotrade import plotter\n",
    "from pyalgotrade.stratanalyzer import returns\n",
    "from pyalgotrade.stratanalyzer import sharpe\n",
    "from pyalgotrade.utils import stats as pytechstats\n",
    "import datetime as dt\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Change this to your directory structure\n",
    "\n",
    "download_dir = '/Users/shadmanspc/Desktop/ADA/A2'\n",
    "\n",
    "#'Specify the stock name in an array \n",
    "\n",
    "#Can do for any number of stocks just append the stock name in the stock array and download it\n",
    "#it from a yahoo finance accordingly\n",
    "#I took training from 2014-1-1 to 2018-12-31.\n",
    "\n",
    "stocks = ['ASX.AX']\n",
    "\n",
    "# keys from yahoo are different from what qstk library expects\n",
    "#\n",
    "yahoo_keys = ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
    "qstk_keys = ['open', 'high', 'low', 'close', 'volume', 'actual_close']\n",
    "#Keep track of the stocks and its data\n",
    "raw_training_data = {}\n",
    "# cloned for iteration, will remove those stocks from master stocks list if\n",
    "\n",
    "# Initially designed for fetching direcrly from url but apparently everything has been deprecated.\n",
    "\n",
    "stocks_clone = [s for s in stocks]\n",
    "\n",
    "for s in stocks_clone:\n",
    "    #Change the filename to stockname_training.csv\n",
    "  \n",
    "    file_name = download_dir + \"/\"+ s + '_training'+'.csv'\n",
    "    #print(file_name)\n",
    "    if(os.path.isfile(file_name)) :\n",
    "        raw_training_data[s] = pd.read_csv(file_name)\n",
    "        \n",
    "#I try to mimick the qstk library but this no longer available so I manipulate the data to my model\n",
    "#to the way I believe qstk library would work\n",
    "        \n",
    "\n",
    "def sanitizedataforqstk(frame):\n",
    "    data = {}\n",
    "    for k in yahoo_keys:\n",
    "        key_df = pd.DataFrame()\n",
    "        for s in stocks:\n",
    "            dates = np.array([dt.datetime.strptime(t, \"%Y-%m-%d\") for t in frame[s]['Date']])\n",
    "            key_df[s] = pd.Series(data=frame[s][k].values, index=dates).sort_index(ascending=True)\n",
    "        data[k] = key_df\n",
    "\n",
    "    # sanitize to use the earlier keys\n",
    "    data[qstk_keys[0]] = data[yahoo_keys[0]]\n",
    "    data[qstk_keys[1]] = data[yahoo_keys[1]]\n",
    "    data[qstk_keys[2]] = data[yahoo_keys[2]]\n",
    "    data[qstk_keys[3]] = data[yahoo_keys[3]]\n",
    "    data[qstk_keys[4]] = data[yahoo_keys[4]]\n",
    "    data[qstk_keys[5]] = data[yahoo_keys[5]]\n",
    "    del data[yahoo_keys[0]]\n",
    "    del data[yahoo_keys[1]]\n",
    "    del data[yahoo_keys[2]]\n",
    "    del data[yahoo_keys[3]]\n",
    "    del data[yahoo_keys[4]]\n",
    "    del data[yahoo_keys[5]]\n",
    "    for key in qstk_keys:\n",
    "        data[key] = data[key].fillna(method='ffill')\n",
    "        data[key] = data[key].fillna(method='bfill')\n",
    "        data[key] = data[key].fillna(1.0)\n",
    "\n",
    "    return data\n",
    "\n",
    "training_data = sanitizedataforqstk(raw_training_data)\n",
    "#print(training_data)\n",
    "\n",
    "#This code is copied from https://github.com/tuckerbalch/QSTK/blob/master/qstkfeat/features.py\n",
    "#This library does is not supported anymore so I do my manipulation\n",
    "#This code calculates moving average\n",
    "def featMA( dData, lLookback=30, bRel=True, b_human=False ):\n",
    "    '''\n",
    "    @summary: Calculate moving average\n",
    "    @param dData: Dictionary of data to use\n",
    "    @param lLookback: Number of days to look in the past\n",
    "    @param b_human: if true return dataframe to plot\n",
    "    @return: DataFrame array containing values\n",
    "    '''\n",
    "    \n",
    "    dfPrice = dData['close']\n",
    "    \n",
    "    dfRet = dfPrice.rolling(lLookback).mean()\n",
    "    #ts_log.rolling(12).mean()\n",
    "    \n",
    "    if bRel:\n",
    "        dfRet = dfRet / dfPrice\n",
    "    if b_human:  \n",
    "        data2 = dfRet * dData['close']\n",
    "        data3 = pand.DataFrame({\"Raw\":data2[data2.columns[0]]})\n",
    "        for sym in dfRet.columns:\n",
    "            if sym != '$SPX' and sym != '$VIX':\n",
    "                data3[sym + \" Moving Average\"] = data2[sym]\n",
    "                data3[sym] = dData['close'][sym]\n",
    "        del data3['Raw']\n",
    "        return data3\n",
    "    return dfRet\n",
    "\n",
    "ma_training=featMA(training_data,bRel=False).fillna(0.0)\n",
    "#Filling not applicable values with mean instead of NA\n",
    "#ma_training=ma_training.fillna(ma_training['ASX.AX'].mean())\n",
    "\n",
    "#This code is copied from https://github.com/tuckerbalch/QSTK/blob/master/qstkfeat/features.py\n",
    "#This library does is not supported anymore so I do my manipulation\n",
    "#This code calculates momentum\n",
    "\n",
    "def returnize0(nds):\n",
    "    \"\"\"\n",
    "    @summary Computes stepwise (usually daily) returns relative to 0, where\n",
    "    0 implies no change in value.\n",
    "    @return the array is revised in place\n",
    "    \"\"\"\n",
    "    s= np.shape(nds)\n",
    "    if len(s)==1:\n",
    "        nds=np.expand_dims(nds,1)\n",
    "    #print(s)\n",
    "    nds[1:, :] = (nds[1:, :] - nds[0:-1]) / abs(nds[0:-1])\n",
    "    nds[0, :] = np.zeros(nds.shape[1])\n",
    "    \n",
    "    #return nds\n",
    "\n",
    "def featMomentum(dData, lLookback=20, b_human=False ):\n",
    "    '''\n",
    "    @summary: N day cumulative return (based on 1) indicator\n",
    "    @param dData: Dictionary of data to use\n",
    "    @param lLookback: Number of days to look in the past\n",
    "    @param b_human: if true return dataframe to plot\n",
    "    @return: DataFrame array containing values\n",
    "    '''\n",
    "    if b_human:\n",
    "        for sym in dData['close']:\n",
    "            x=1000/dData['close'][sym][0]\n",
    "            dData['close'][sym]=dData['close'][sym]*x\n",
    "        return dData['close']\n",
    "    dfPrice = dData['close'].copy()\n",
    "    #print(dfPrice.values)\n",
    "    \n",
    "    #Calculate Returns\n",
    "    returnize0(dfPrice.values)\n",
    "    \n",
    "    #Calculate rolling sum\n",
    "    dfRet = dfPrice.rolling(lLookback).sum()\n",
    "    #print(dfRet.head(100))\n",
    "    \n",
    "    \n",
    "    return dfRet\n",
    "\n",
    "mom_training=featMomentum(training_data).fillna(0.0)\n",
    "#Filling not applicable values with mean instead of NA\n",
    "#mom_training=mom_training.fillna(mom_training['ASX.AX'].mean())\n",
    "#print(mom_training.head(100))\n",
    "\n",
    "# This code calculates RSI\n",
    "\n",
    "def featRSI( dData, lLookback=14,  b_human=False):\n",
    "    '''\n",
    "    @summary: Calculate RSI\n",
    "    @param dData: Dictionary of data to use\n",
    "    @param lLookback: Number of days to look in the past, 14 is standard\n",
    "    @param b_human: if true return dataframe to plot\n",
    "    @return: DataFrame array containing values\n",
    "    '''\n",
    "\n",
    "    # create deltas per day\n",
    "    delta = dData['close'].diff()\n",
    "    #-----------\n",
    "    dUp, dDown = delta.copy(), delta.copy()\n",
    "    dUp[dUp < 0] = 0\n",
    "    dDown[dDown > 0] = 0\n",
    "\n",
    "    RolUp = dUp.rolling(14).mean()\n",
    "    RolDown = dDown.rolling(14).mean().abs()\n",
    "    \n",
    "\n",
    "    RS = RolUp / RolDown\n",
    "    rsi= 100.0 - (100.0 / (1.0 + RS))\n",
    "    return rsi\n",
    "\n",
    "rsi_training=featRSI(training_data).fillna(0.0)\n",
    "#Filling not applicable values with mean instead of NA\n",
    "#rsi_training=rsi_training.fillna(rsi_training['ASX.AX'].mean())\n",
    "#print(rsi_training.head(100))\n",
    "\n",
    "#If I want to predict the stock price for the next few days\n",
    "#The current data set has values from 01/01/2019-today\n",
    "currentDate = dt.date.today()\n",
    "#YOu can take -30 as this dataset is relatively not needed however it must have 30 days as simple moving average has a lookback of 30 days\n",
    "oldDate = currentDate + dt.timedelta(days=-30)\n",
    "raw_current_data = {}\n",
    "for s in stocks_clone:\n",
    "    file_name = download_dir + \"/\"+ s + '_current'+'.csv'\n",
    "    #print(file_name)\n",
    "    if(os.path.isfile(file_name)) :\n",
    "      \n",
    "        raw_current_data[s] = pd.read_csv(file_name)\n",
    "    \n",
    "\n",
    "current_data = sanitizedataforqstk(raw_current_data)\n",
    "#print(current_data)\n",
    "\n",
    "#DEAP LIBRARY IS TAKEN\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "# basic initialization for deap\n",
    "def initDeap():\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "    # stochastic removed as High and Low can't be calculated for\n",
    "    IND_SIZE = 3  \n",
    "    # registerd coeff alias to coefficient function\n",
    "    toolbox.register(\"coeffs\", coefficient)\n",
    "    # individual alias registerd to tools.initRepeat\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.coeffs, n=IND_SIZE)\n",
    "    # population alias registered\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    # evaluate fucntion registered to computeFitness function\n",
    "    toolbox.register(\"evaluate\", compute_fitness)\n",
    "    toolbox.register(\"mate\", tools.cxSimulatedBinary, eta=0.3)\n",
    "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0.0, sigma=1.0, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=5)\n",
    "\n",
    "# 1. rsi, 2. ma, 3. mom above is the order of coefficients removed pivot\n",
    "# point and stochastic oscillator as one of the technical indicator, because\n",
    "# lets say we are running this for the next 6 months,in that case we would\n",
    "# not have the value of high, low of future. as such for future we can't use\n",
    "# it.\n",
    "def compute_fitness(individual):\n",
    "    error = 0.0\n",
    "    count = 0\n",
    "    for key in stocks:\n",
    "        # difference in RSI between day1 and day1 + 1\n",
    "        rsidiff = rsi_training[key] - rsi_training[key].shift()\n",
    "        # difference in moving average between day1 and day1 + 1\n",
    "        madiff = ma_training[key] - ma_training[key].shift()\n",
    "        # difference in momentum between day1 and day1 + 1\n",
    "        momdiff = mom_training[key] - mom_training[key].shift()\n",
    "        per_stock_count = 0\n",
    "        dataframe_index = training_data[qstk_keys[3]][key].index.tolist()\n",
    "        for (date, val) in rsi_training[key].iteritems():\n",
    "            next_day = dataframe_index[per_stock_count + 1] if\\\n",
    "                per_stock_count <= len(dataframe_index) - 1 else None\n",
    "            if not np.isnan(rsidiff[date]) and next_day is not None:\n",
    "                #            Fitness defined as\n",
    "                # market close (day2) - [ rsi difference between consecutive day * (coeff 1) +\n",
    "                # moving average difference between consecutive day * (coeff 2) +\n",
    "                # momentum difference between consecutive day * (coeff 3) +\n",
    "                \n",
    "                # Objective is to minimize the summation of squares of the above differences\n",
    "                ft = (rsidiff[date]) * individual[0] + (madiff[date]) * individual[1] \\\n",
    "                     + (momdiff[date]) * individual[2]\n",
    "                ft = ft + training_data[qstk_keys[3]][key][date]\n",
    "                error = error + np.square(training_data[qstk_keys[3]][key][next_day] - ft)\n",
    "                count = count + 1\n",
    "                per_stock_count = per_stock_count + 1\n",
    "    # dividing by total count gives the mean square error, which we want to minimize\n",
    "    return (error / count,)\n",
    "\n",
    "\n",
    "def coefficient():\n",
    "    return random.random()\n",
    "\n",
    "def predict(individual, days=1):\n",
    "    prediction_series= []\n",
    "    for d in list(range(days)):\n",
    "        # calculate the rsi, ma and momentum\n",
    "        # with each preddiction the underluing current_data dataframe is updated,\n",
    "        # so we get the updated rsi for all the days\n",
    "        rsi_current = featRSI(current_data)\n",
    "        rsi_current=rsi_current.fillna(rsi_training['ASX.AX'].mean())\n",
    "        \n",
    "        ma_current = featMA(current_data, bRel=False)\n",
    "        ma_current=ma_current.fillna(ma_training['ASX.AX'].mean())\n",
    "        \n",
    "        mom_current = featMomentum(current_data)\n",
    "        mom_current=mom_current.fillna(mom_training['ASX.AX'].mean())\n",
    "\n",
    "        for key in stocks:\n",
    "            # get the last valid date for which data is present\n",
    "            last_date_with_data =\\\n",
    "                current_data[qstk_keys[3]][key].last_valid_index()\n",
    "            #print(\"last-date\")\n",
    "            print(last_date_with_data)\n",
    "            next_date = last_date_with_data + dt.timedelta(days=1)\n",
    "            # calculate the rsi,ma and momentum diff across consecutive days \n",
    "            rsi_current_diff = rsi_current[key] - rsi_current[key].shift()\n",
    "            #print(\"rsi_diff\")\n",
    "            #print(rsi_current_diff)\n",
    "            \n",
    "            ma_current_diff = ma_current[key] - ma_current[key].shift()\n",
    "            #print(\"ma_diff\")\n",
    "            #print(ma_current_diff)\n",
    "            mom_current_diff = mom_current[key] - mom_current[key].shift()\n",
    "            #print(\"mom_diff\")\n",
    "            #print(mom_current_diff)\n",
    "            #  calculate the deviation based on the conefficients\n",
    "            deviation = (rsi_current_diff.tail(1).values[0]) * individual[0]\\\n",
    "                + (ma_current_diff.tail(1).values[0]) * individual[1]+\\\n",
    "                (mom_current_diff.tail(1).values[0]) * individual[2]\n",
    "            print(deviation)\n",
    "            # predicted is addition of deviation + current close\n",
    "            predicted_close_next_day = deviation + current_data[qstk_keys[3]][key][last_date_with_data]\n",
    "            # update the current dataframe so we can continue calculating stocks\n",
    "            current_data[qstk_keys[3]][key].set_value(next_date,predicted_close_next_day)\n",
    "            \n",
    "            prediction_series.append((key,next_date,predicted_close_next_day,\n",
    "                                      current_data[qstk_keys[3]][key][last_date_with_data] ,\n",
    "                                      deviation))\n",
    "    \n",
    "    return prediction_series\n",
    "\n",
    "\n",
    "\n",
    "#Get our base model up and Running\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    initDeap()\n",
    "    # population generated\n",
    "    \n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"median\", np.median)\n",
    "    populationSize=50\n",
    "    crossOverProbability=0.5\n",
    "    mutationProbability=0.2\n",
    "    numberOfGeneration=5\n",
    "    minError=100\n",
    "    for x in range(0, 10):\n",
    "        print(\"===========BEGIN============\")\n",
    "        print(x)\n",
    "        pop = toolbox.population(n=populationSize)\n",
    "    # built in algo used with cross over probability = 0.5, mutation probability = 0.2 and number of generation = 5\n",
    "        pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=crossOverProbability, mutpb=mutationProbability, ngen=numberOfGeneration, stats=stats, halloffame=hof,\n",
    "                                           verbose=True)\n",
    "        \n",
    "        print(\"Best individual is: %s\\nwith fitness: %s\" % (hof[0], hof[0].fitness))\n",
    "        meanSquareError=str(hof[0].fitness)\n",
    "        meanSquareError=re.findall(\"\\d+\\.\\d+\", meanSquareError)\n",
    "        print(\"lets see\")\n",
    "        print(meanSquareError)\n",
    "        meanSquareError=float(meanSquareError[0])\n",
    "        if(meanSquareError < minError):\n",
    "            #Select the best fitness\n",
    "            minError=meanSquareError\n",
    "            \n",
    "            print(\"The best fitness from \\n1. %d -populationSize \\n2. %f -crossOverPropability\\\n",
    "                \\n3. %f -mutationProbability\\n4. %f -numberOfGeneration \\n5. %f -error\" %(populationSize,crossOverProbability,mutationProbability,numberOfGeneration,meanSquareError))\n",
    "         \n",
    "        populationSize=populationSize+10\n",
    "        crossOverProbability=crossOverProbability+0.05\n",
    "        mutationProbability=mutationProbability+0.05\n",
    "        numberOfGeneration=numberOfGeneration+2\n",
    "        print(\"===============DONE===================================\")\n",
    "        \n",
    "    # this gives us the coefficients. Once we get the coefficients , we can use this coefficients,\n",
    "    # we can use these to calculate the next day's value based on values on the present day\n",
    "    '''\n",
    "    \n",
    "     # predict for 5 days, change the number of days to get that many days of prediction\n",
    "    prediction_series = predict(hof[0],days=5)\n",
    "    # sorting the prediction series with all entries of same stock together\n",
    "   \n",
    "    prediction_series_sorted = sorted(prediction_series, key=lambda tup: tup[0])\n",
    "    #print(prediction_series)\n",
    "    #print(stocks[0])\n",
    "    \n",
    "    filename = download_dir+'/results_predicted-'+stocks[0]+'Extentedv1-.csv'\n",
    "    #Store our testFileName\n",
    "    testFileName=download_dir+'/ASX.AX-Test.csv'\n",
    "    #load our testFileName\n",
    "    test_file_name= pd.read_csv(testFileName)\n",
    "    closingPrices=test_file_name['Close']\n",
    "    #print(closingPrices)\n",
    "    #print(\"type\")\n",
    "    #print(type(closingPrices))\n",
    "    closingPrices=closingPrices.values.tolist()\n",
    "    #print(closingPrices)\n",
    "    #closingPrices=list(zip(closingPrices))\n",
    "    \n",
    "    \n",
    "    #print(filename)\n",
    "    with open(filename, 'w') as csvfile:\n",
    "        fieldnames = ['stock',\n",
    "                      'date','actual_price','predicted_price','price_prev_day','deviation','movement']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        i=1\n",
    "        writer.writerow({'stock': 'ASX.AX', 'date': '16/09/2019','actual_price': closingPrices[0],'predicted_price': \"Actual Price on 16th\",'price_prev_day': \"NA\",'deviation':\"NA\",'movement':\"NA\"})\n",
    "        for prediction in prediction_series_sorted:\n",
    "            #Classify it as up or down\n",
    "            movement = 'DOWN' if prediction[4] < 0 else 'UP'\n",
    "            #print(closingPrices[i])\n",
    "            writer.writerow(\n",
    "                {'stock': prediction[0], 'date': prediction[1].strftime('%m/%d/%Y'),'actual_price': closingPrices[i],'predicted_price': prediction[2],'price_prev_day': prediction[3],'deviation':prediction[4],'movement':movement})\n",
    "            i=i+1\n",
    "    \n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\"> Summary:<h3> Result of base model was better as it was closer to the the actual prices on 17th however the extentedv1 model provided a lower error </h3></h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
